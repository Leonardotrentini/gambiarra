# ğŸš€ PLANO: Ferramenta de Escaneamento e Download de DomÃ­nio

## ğŸ“‹ Objetivo
Criar uma ferramenta web que:
1. Recebe uma URL de uma pÃ¡gina
2. Escaneia TODO o cÃ³digo/arquivos daquele domÃ­nio
3. Lista todos os arquivos encontrados
4. Permite copiar/baixar arquivos individuais ou em lote

## ğŸ—ï¸ Arquitetura Proposta

### **Stack TecnolÃ³gica:**
- **Frontend:** Next.js 14 (React) + TypeScript + Tailwind CSS
- **Backend:** Next.js API Routes (serverless)
- **Crawling:** Puppeteer ou Cheerio + Axios
- **Download:** Node.js fs + stream

### **Estrutura do Projeto:**
```
gambiarra/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ page.tsx              # Interface principal
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ scan/route.ts     # Endpoint para escanear domÃ­nio
â”‚   â”‚   â””â”€â”€ download/route.ts # Endpoint para download
â”‚   â””â”€â”€ layout.tsx
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ crawler.ts            # LÃ³gica de crawling
â”‚   â”œâ”€â”€ file-discovery.ts     # Descoberta de arquivos
â”‚   â””â”€â”€ downloader.ts         # LÃ³gica de download
â”œâ”€â”€ types/
â”‚   â””â”€â”€ index.ts              # Tipos TypeScript
â””â”€â”€ package.json
```

## ğŸ”„ Fluxo de Funcionamento

### **Etapa 1: Entrada do UsuÃ¡rio**
- Interface com campo de input para URL
- BotÃ£o "Escanear DomÃ­nio"
- ValidaÃ§Ã£o de URL

### **Etapa 2: Escaneamento (Backend)**
1. **Crawling Inicial:**
   - Acessa a URL fornecida
   - Extrai HTML da pÃ¡gina
   - Identifica o domÃ­nio base

2. **Descoberta de Arquivos:**
   - Analisa HTML para encontrar:
     - Links internos (`<a href>`)
     - Scripts (`<script src>`)
     - Estilos (`<link rel="stylesheet">`)
     - Imagens (`<img src>`)
     - Fontes (`@font-face`, `<link rel="font">`)
     - Assets diversos (vÃ­deos, PDFs, etc.)

3. **Crawling Recursivo:**
   - Visita cada link interno encontrado
   - MantÃ©m lista de URLs jÃ¡ visitadas (evitar loops)
   - Respeita robots.txt (opcional)
   - Limita profundidade (configurÃ¡vel)

4. **Coleta de Arquivos:**
   - Lista todos os arquivos Ãºnicos encontrados
   - Categoriza por tipo (HTML, CSS, JS, Imagens, etc.)
   - Extrai metadados (tamanho, tipo MIME, URL completa)

### **Etapa 3: ExibiÃ§Ã£o (Frontend)**
- Lista de arquivos encontrados
- Filtros por tipo de arquivo
- Busca/filtro de arquivos
- Contador de arquivos por categoria
- Status do escaneamento (progresso)

### **Etapa 4: Download**
- **Download Individual:**
  - BotÃ£o ao lado de cada arquivo
  - Download direto do arquivo original

- **Download em Lote:**
  - BotÃ£o "Baixar Todos"
  - Cria estrutura de pastas local
  - Baixa todos os arquivos mantendo estrutura
  - Gera ZIP com todos os arquivos (opcional)

## ğŸ› ï¸ Funcionalidades Detalhadas

### **1. Crawler Inteligente**
- âœ… Respeita CORS e polÃ­ticas do site
- âœ… Detecta SPA (Single Page Applications)
- âœ… Suporta JavaScript renderizado (Puppeteer)
- âœ… Evita loops infinitos
- âœ… Limite de requisiÃ§Ãµes por segundo (rate limiting)
- âœ… Timeout configurÃ¡vel

### **2. Descoberta de Arquivos**
- âœ… HTML, CSS, JavaScript
- âœ… Imagens (JPG, PNG, SVG, WebP, etc.)
- âœ… Fontes (WOFF, WOFF2, TTF, etc.)
- âœ… VÃ­deos e Ã¡udios
- âœ… Documentos (PDF, DOC, etc.)
- âœ… Arquivos de dados (JSON, XML, etc.)
- âœ… Arquivos estÃ¡ticos diversos

### **3. Interface do UsuÃ¡rio**
- âœ… Design moderno e responsivo
- âœ… Indicador de progresso do escaneamento
- âœ… Lista filtrada e pesquisÃ¡vel
- âœ… Preview de arquivos (quando possÃ­vel)
- âœ… EstatÃ­sticas (total de arquivos, tamanho, etc.)

### **4. Sistema de Download**
- âœ… Download individual
- âœ… Download em lote
- âœ… ManutenÃ§Ã£o da estrutura de pastas
- âœ… GeraÃ§Ã£o de ZIP (opcional)
- âœ… Barra de progresso para downloads

## âš ï¸ ConsideraÃ§Ãµes Importantes

### **LimitaÃ§Ãµes Legais e Ã‰ticas:**
- âš ï¸ Respeitar termos de uso dos sites
- âš ï¸ NÃ£o usar para sites que proÃ­bem scraping
- âš ï¸ Rate limiting para nÃ£o sobrecarregar servidores
- âš ï¸ Aviso legal na interface

### **Desafios TÃ©cnicos:**
- ğŸ”´ Sites com autenticaÃ§Ã£o
- ğŸ”´ ConteÃºdo gerado dinamicamente via JS
- ğŸ”´ Arquivos protegidos por CORS
- ğŸ”´ Sites muito grandes (limite de tempo/memÃ³ria)
- ğŸ”´ Arquivos em CDNs externos

## ğŸ“¦ DependÃªncias NecessÃ¡rias

```json
{
  "dependencies": {
    "next": "^14.0.0",
    "react": "^18.0.0",
    "typescript": "^5.0.0",
    "puppeteer": "^21.0.0",
    "cheerio": "^1.0.0",
    "axios": "^1.6.0",
    "jszip": "^3.10.0",
    "mime-types": "^2.1.0"
  }
}
```

## ğŸ¯ PrÃ³ximos Passos

1. âœ… Criar estrutura do projeto Next.js
2. âœ… Configurar TypeScript e dependÃªncias
3. âœ… Implementar interface bÃ¡sica
4. âœ… Criar crawler bÃ¡sico
5. âœ… Implementar descoberta de arquivos
6. âœ… Criar interface de listagem
7. âœ… Implementar sistema de download
8. âœ… Adicionar funcionalidades avanÃ§adas
9. âœ… Testes e refinamentos

